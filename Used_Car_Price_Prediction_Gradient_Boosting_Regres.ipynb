{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.13",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "none",
      "dataSources": [
        {
          "sourceId": 8580803,
          "sourceType": "datasetVersion",
          "datasetId": 5131699
        }
      ],
      "dockerImageVersionId": 30715,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": false
    },
    "colab": {
      "name": "Used Car Price Prediction Gradient Boosting Regres",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dominiquedeveraux/Used-Car-Prediction-Gradient-Boosting-Regression-Model/blob/main/Used_Car_Price_Prediction_Gradient_Boosting_Regres.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "source": [
        "\n",
        "# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES\n",
        "# TO THE CORRECT LOCATION (/kaggle/input) IN YOUR NOTEBOOK,\n",
        "# THEN FEEL FREE TO DELETE THIS CELL.\n",
        "# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON\n",
        "# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR\n",
        "# NOTEBOOK.\n",
        "\n",
        "import os\n",
        "import sys\n",
        "from tempfile import NamedTemporaryFile\n",
        "from urllib.request import urlopen\n",
        "from urllib.parse import unquote, urlparse\n",
        "from urllib.error import HTTPError\n",
        "from zipfile import ZipFile\n",
        "import tarfile\n",
        "import shutil\n",
        "\n",
        "CHUNK_SIZE = 40960\n",
        "DATA_SOURCE_MAPPING = 'kagglex-cohort4:https%3A%2F%2Fstorage.googleapis.com%2Fkaggle-data-sets%2F5131699%2F8580803%2Fbundle%2Farchive.zip%3FX-Goog-Algorithm%3DGOOG4-RSA-SHA256%26X-Goog-Credential%3Dgcp-kaggle-com%2540kaggle-161607.iam.gserviceaccount.com%252F20240601%252Fauto%252Fstorage%252Fgoog4_request%26X-Goog-Date%3D20240601T213924Z%26X-Goog-Expires%3D259200%26X-Goog-SignedHeaders%3Dhost%26X-Goog-Signature%3D4fccf2ec334ec2e00b08a61dffb80385fae5d172f3cb658db393d68c6966214f93ff69d302c96615a3a0a3e8ce6c613bbfad9aa2e4fee083e6c9a7132568a56e7189b95d5ef4b9b789880d8fc177eb2b7183f90d3b3e2d92beb7d48ae6c5b212bafb9cab5e1374642495360e61a0df6c66cec39dd9fc5dff30fba9f5aee0c1436c05cc7696f47e9cea2f487dc0f13e067e5e192c71f192e37b5f1740dd1b58346a3fffc552a92aa2f94f52091397a07b146ebae3b1c61f2843959ef74dfb8eb95d069a046e063bc17dbfdbb4fd0c2d807919208cee540308f11b348e2d2727195a563a75b0055bd28d0297fe72ac72386fb95f6f578d8d7129d9ba62b800b173'\n",
        "\n",
        "KAGGLE_INPUT_PATH='/kaggle/input'\n",
        "KAGGLE_WORKING_PATH='/kaggle/working'\n",
        "KAGGLE_SYMLINK='kaggle'\n",
        "\n",
        "!umount /kaggle/input/ 2> /dev/null\n",
        "shutil.rmtree('/kaggle/input', ignore_errors=True)\n",
        "os.makedirs(KAGGLE_INPUT_PATH, 0o777, exist_ok=True)\n",
        "os.makedirs(KAGGLE_WORKING_PATH, 0o777, exist_ok=True)\n",
        "\n",
        "try:\n",
        "  os.symlink(KAGGLE_INPUT_PATH, os.path.join(\"..\", 'input'), target_is_directory=True)\n",
        "except FileExistsError:\n",
        "  pass\n",
        "try:\n",
        "  os.symlink(KAGGLE_WORKING_PATH, os.path.join(\"..\", 'working'), target_is_directory=True)\n",
        "except FileExistsError:\n",
        "  pass\n",
        "\n",
        "for data_source_mapping in DATA_SOURCE_MAPPING.split(','):\n",
        "    directory, download_url_encoded = data_source_mapping.split(':')\n",
        "    download_url = unquote(download_url_encoded)\n",
        "    filename = urlparse(download_url).path\n",
        "    destination_path = os.path.join(KAGGLE_INPUT_PATH, directory)\n",
        "    try:\n",
        "        with urlopen(download_url) as fileres, NamedTemporaryFile() as tfile:\n",
        "            total_length = fileres.headers['content-length']\n",
        "            print(f'Downloading {directory}, {total_length} bytes compressed')\n",
        "            dl = 0\n",
        "            data = fileres.read(CHUNK_SIZE)\n",
        "            while len(data) > 0:\n",
        "                dl += len(data)\n",
        "                tfile.write(data)\n",
        "                done = int(50 * dl / int(total_length))\n",
        "                sys.stdout.write(f\"\\r[{'=' * done}{' ' * (50-done)}] {dl} bytes downloaded\")\n",
        "                sys.stdout.flush()\n",
        "                data = fileres.read(CHUNK_SIZE)\n",
        "            if filename.endswith('.zip'):\n",
        "              with ZipFile(tfile) as zfile:\n",
        "                zfile.extractall(destination_path)\n",
        "            else:\n",
        "              with tarfile.open(tfile.name) as tarfile:\n",
        "                tarfile.extractall(destination_path)\n",
        "            print(f'\\nDownloaded and uncompressed: {directory}')\n",
        "    except HTTPError as e:\n",
        "        print(f'Failed to load (likely expired) {download_url} to path {destination_path}')\n",
        "        continue\n",
        "    except OSError as e:\n",
        "        print(f'Failed to load {download_url} to path {destination_path}')\n",
        "        continue\n",
        "\n",
        "print('Data source import complete.')\n"
      ],
      "metadata": {
        "id": "G2B7Ii99vkgY"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# This Python 3 environment comes with many helpful analytics libraries installed\n",
        "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
        "# For example, here's several helpful packages to load\n",
        "\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "\n",
        "# Input data files are available in the read-only \"../input/\" directory\n",
        "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
        "\n",
        "import os\n",
        "for dirname, _, filenames in os.walk('/kaggle/input/kagglex-cohort4/kagglex-cohort4'):\n",
        "    for filename in filenames:\n",
        "        print(os.path.join(dirname, filename))\n",
        "\n",
        "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\"\n",
        "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
      ],
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "execution": {
          "iopub.status.busy": "2024-06-01T20:32:34.414073Z",
          "iopub.execute_input": "2024-06-01T20:32:34.414606Z",
          "iopub.status.idle": "2024-06-01T20:32:34.424166Z",
          "shell.execute_reply.started": "2024-06-01T20:32:34.414554Z",
          "shell.execute_reply": "2024-06-01T20:32:34.422778Z"
        },
        "trusted": true,
        "id": "NgcwVcBzvkgb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "train_df = pd.read_csv('/kaggle/input/kagglex-cohort4/kagglex-cohort4/train.csv')\n",
        "test_df = pd.read_csv('/kaggle/input/kagglex-cohort4/kagglex-cohort4/test.csv')\n",
        "\n",
        "print(train_df.head())\n",
        "print(test_df.head())\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-06-01T20:32:34.426298Z"
        },
        "trusted": true,
        "id": "VX6725j1vkgb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Reload the dataframes\n",
        "train_df = pd.read_csv('/kaggle/input/kagglex-cohort4/kagglex-cohort4/train.csv')\n",
        "test_df = pd.read_csv('/kaggle/input/kagglex-cohort4/kagglex-cohort4/test.csv')\n",
        "\n",
        "# Print the column names to verify\n",
        "print(train_df.columns)\n",
        "print(test_df.columns)\n",
        "\n",
        "# Perform one-hot encoding\n",
        "train_df = pd.get_dummies(train_df, columns=['ext_col', 'int_col', 'accident', 'clean_title'])\n",
        "test_df = pd.get_dummies(test_df, columns=['ext_col', 'int_col', 'accident', 'clean_title'])\n",
        "\n",
        "print(train_df.head(2))\n",
        "print(test_df.head(2))"
      ],
      "metadata": {
        "execution": {
          "iopub.status.idle": "2024-06-01T20:32:34.994547Z",
          "shell.execute_reply.started": "2024-06-01T20:32:34.673194Z",
          "shell.execute_reply": "2024-06-01T20:32:34.993344Z"
        },
        "trusted": true,
        "id": "MHVqwTQKvkgb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Iterate through columns in train_df\n",
        "for col in train_df.columns:\n",
        "    if train_df[col].dtype == 'object':\n",
        "        train_df[col] = pd.to_numeric(train_df[col], errors='coerce')\n",
        "\n",
        "# Iterate through columns in test_df\n",
        "for col in test_df.columns:\n",
        "    if test_df[col].dtype == 'object':\n",
        "        test_df[col] = pd.to_numeric(test_df[col], errors='coerce')\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-06-01T20:32:34.995781Z",
          "iopub.execute_input": "2024-06-01T20:32:34.996106Z",
          "iopub.status.idle": "2024-06-01T20:32:35.380065Z",
          "shell.execute_reply.started": "2024-06-01T20:32:34.996078Z",
          "shell.execute_reply": "2024-06-01T20:32:35.378842Z"
        },
        "trusted": true,
        "id": "R6QXzwrTvkgb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('Train shape before removing NaN:', train_df.shape)\n",
        "train_df = train_df.dropna()\n",
        "print('Train shape after removing NaN:', train_df.shape)\n",
        "\n",
        "print('Test shape before removing NaN:', test_df.shape)\n",
        "test_df = test_df.dropna()\n",
        "print('Test shape after removing NaN:', test_df.shape)\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-06-01T20:32:35.382491Z",
          "iopub.execute_input": "2024-06-01T20:32:35.382863Z",
          "iopub.status.idle": "2024-06-01T20:32:35.410508Z",
          "shell.execute_reply.started": "2024-06-01T20:32:35.382832Z",
          "shell.execute_reply": "2024-06-01T20:32:35.409195Z"
        },
        "trusted": true,
        "id": "dyw0Nsfdvkgb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check the number of NaN values in each column of train_df\n",
        "print(train_df.isna().sum())\n",
        "\n",
        "# Check the number of NaN values in each column of test_df\n",
        "print(test_df.isna().sum())"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-06-01T20:32:35.414899Z",
          "iopub.execute_input": "2024-06-01T20:32:35.415229Z",
          "iopub.status.idle": "2024-06-01T20:32:35.426175Z"
        },
        "trusted": true,
        "id": "hT-SPsJMvkgb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fill NaN values in numerical columns with the mean\n",
        "train_df = train_df.fillna(train_df.mean(numeric_only=True))\n",
        "\n",
        "# Fill NaN values in numerical columns with the mean\n",
        "test_df = test_df.fillna(test_df.mean(numeric_only=True))\n",
        "\n",
        "print('Train shape after imputing NaN:', train_df.shape)\n",
        "print('Test shape after imputing NaN:', test_df.shape)\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-06-01T20:32:35.427582Z",
          "iopub.execute_input": "2024-06-01T20:32:35.427949Z",
          "iopub.status.idle": "2024-06-01T20:32:35.585425Z"
        },
        "trusted": true,
        "id": "n-uMgjzWvkgb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Reload the data\n",
        "train_df = pd.read_csv('/kaggle/input/kagglex-cohort4/kagglex-cohort4/train.csv')\n",
        "test_df = pd.read_csv('/kaggle/input/kagglex-cohort4/kagglex-cohort4/test.csv')\n",
        "\n",
        "# Perform one-hot encoding again\n",
        "train_df = pd.get_dummies(train_df, columns=['ext_col', 'int_col', 'accident', 'clean_title'])\n",
        "test_df = pd.get_dummies(test_df, columns=['ext_col', 'int_col', 'accident', 'clean_title'])\n",
        "\n",
        "# Remove string values from all columns\n",
        "for col in train_df.columns:\n",
        "    if train_df[col].dtype == 'object':\n",
        "        train_df[col] = pd.to_numeric(train_df[col], errors='coerce')\n",
        "\n",
        "for col in test_df.columns:\n",
        "    if test_df[col].dtype == 'object':\n",
        "        test_df[col] = pd.to_numeric(test_df[col], errors='coerce')\n",
        "\n",
        "# Fill NaN values in numerical columns with the mean\n",
        "train_df = train_df.fillna(train_df.mean(numeric_only=True))\n",
        "test_df = test_df.fillna(test_df.mean(numeric_only=True))\n",
        "\n",
        "print('Train shape after imputing NaN:', train_df.shape)\n",
        "print('Test shape after imputing NaN:', test_df.shape)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-06-01T20:32:35.586652Z",
          "iopub.execute_input": "2024-06-01T20:32:35.586968Z",
          "iopub.status.idle": "2024-06-01T20:32:36.500862Z"
        },
        "trusted": true,
        "id": "lkdZQIbSvkgc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import GradientBoostingRegressor\n",
        "\n",
        "# Instantiate the model\n",
        "model = GradientBoostingRegressor()\n",
        "\n",
        "# Separate features and target variable\n",
        "X = train_df.drop('price', axis=1)\n",
        "y = train_df['price']\n",
        "\n",
        "# Impute NaN values with mean for numerical columns\n",
        "X = X.fillna(X.mean(numeric_only=True))\n",
        "\n",
        "# Impute NaN values with 0 for one-hot encoded columns\n",
        "X = X.fillna(0)\n",
        "\n",
        "# Drop original non-numerical columns\n",
        "X = X.select_dtypes(exclude=['object'])\n",
        "\n",
        "# Train the model\n",
        "model.fit(X, y)"
      ],
      "metadata": {
        "trusted": true,
        "id": "RSDl4bZIvkgc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a DataFrame with 'id' and 'price' columns\n",
        "result_df = pd.DataFrame({'id': test_df['id'], 'price': predicted_prices})\n",
        "\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-06-01T20:55:09.126878Z",
          "iopub.execute_input": "2024-06-01T20:55:09.127325Z",
          "iopub.status.idle": "2024-06-01T20:55:09.136539Z",
          "shell.execute_reply.started": "2024-06-01T20:55:09.127269Z",
          "shell.execute_reply": "2024-06-01T20:55:09.135188Z"
        },
        "trusted": true,
        "id": "6nU6-s4kvkgc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result_df = result_df.sort_values('price', ascending=True)\n",
        "print(result_df)\n",
        "\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-06-01T20:55:31.589191Z",
          "iopub.execute_input": "2024-06-01T20:55:31.589602Z",
          "iopub.status.idle": "2024-06-01T20:55:31.60272Z",
          "shell.execute_reply.started": "2024-06-01T20:55:31.58957Z",
          "shell.execute_reply": "2024-06-01T20:55:31.601572Z"
        },
        "trusted": true,
        "id": "8x-xgf5hvkgc"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}